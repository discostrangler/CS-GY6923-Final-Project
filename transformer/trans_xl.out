Using device: cuda  |  mode: train
Vocab size: 103
Model config for xl: {'n_layers': 12, 'n_heads': 12, 'd_model': 768}
Model xl has 85,331,712 trainable parameters
GPU memory at start: 328.51 MB
Loading datasets (memmap)...
Train effective tokens: 117,599,999
Tokens per step:        16,384
Steps per epoch:        7,177
Starting training for exactly 1 epoch
Step 50/7177  loss 2.4078  lr 0.000043
Step 100/7177  loss 1.8205  lr 0.000085
Step 150/7177  loss 1.7405  lr 0.000127
Step 200/7177  loss 1.5869  lr 0.000168
[eval] step 200  val_loss 1.6425
Step 250/7177  loss 1.5372  lr 0.000210
Step 300/7177  loss 1.7126  lr 0.000252
Step 350/7177  loss 1.5872  lr 0.000294
Step 400/7177  loss 1.6005  lr 0.000300
[eval] step 400  val_loss 1.4245
Step 450/7177  loss 1.2170  lr 0.000300
Step 500/7177  loss 1.3794  lr 0.000300
Step 550/7177  loss 1.1477  lr 0.000299
Step 600/7177  loss 1.3773  lr 0.000299
[eval] step 600  val_loss 1.1794
Step 650/7177  loss 1.2769  lr 0.000299
Step 700/7177  loss 1.1483  lr 0.000298
Step 750/7177  loss 1.1833  lr 0.000298
Step 800/7177  loss 1.0194  lr 0.000297
[eval] step 800  val_loss 1.0691
Step 850/7177  loss 1.1238  lr 0.000296
Step 900/7177  loss 1.0729  lr 0.000295
Step 950/7177  loss 1.3531  lr 0.000294
Step 1000/7177  loss 0.9257  lr 0.000293
[eval] step 1000  val_loss 0.9719
Step 1050/7177  loss 0.9786  lr 0.000292
Step 1100/7177  loss 1.1659  lr 0.000291
Step 1150/7177  loss 0.9357  lr 0.000290
Step 1200/7177  loss 0.9366  lr 0.000289
[eval] step 1200  val_loss 0.9084
Step 1250/7177  loss 0.8397  lr 0.000288
Step 1300/7177  loss 0.8972  lr 0.000286
Step 1350/7177  loss 1.0075  lr 0.000285
Step 1400/7177  loss 0.7934  lr 0.000283
[eval] step 1400  val_loss 0.8594
Step 1450/7177  loss 1.0264  lr 0.000281
Step 1500/7177  loss 0.8475  lr 0.000280
Step 1550/7177  loss 1.0474  lr 0.000278
Step 1600/7177  loss 0.8909  lr 0.000276
[eval] step 1600  val_loss 0.8222
Step 1650/7177  loss 0.8809  lr 0.000274
Step 1700/7177  loss 0.7894  lr 0.000272
Step 1750/7177  loss 0.7352  lr 0.000270
Step 1800/7177  loss 0.8127  lr 0.000268
[eval] step 1800  val_loss 0.7804
Step 1850/7177  loss 0.6827  lr 0.000266
Step 1900/7177  loss 0.7252  lr 0.000264
Step 1950/7177  loss 0.7592  lr 0.000261
Step 2000/7177  loss 0.7731  lr 0.000259
[eval] step 2000  val_loss 0.7654
Step 2050/7177  loss 0.7842  lr 0.000257
Step 2100/7177  loss 0.6918  lr 0.000254
Step 2150/7177  loss 0.8401  lr 0.000252
Step 2200/7177  loss 0.7156  lr 0.000249
[eval] step 2200  val_loss 0.7480
Step 2250/7177  loss 0.6652  lr 0.000247
Step 2300/7177  loss 0.5286  lr 0.000244
Step 2350/7177  loss 0.7095  lr 0.000241
Step 2400/7177  loss 0.5372  lr 0.000238
[eval] step 2400  val_loss 0.7211
Step 2450/7177  loss 0.7682  lr 0.000236
Step 2500/7177  loss 0.5896  lr 0.000233
Step 2550/7177  loss 0.7312  lr 0.000230
Step 2600/7177  loss 0.4810  lr 0.000227
[eval] step 2600  val_loss 0.7058
Step 2650/7177  loss 0.7018  lr 0.000224
Step 2700/7177  loss 0.6947  lr 0.000221
Step 2750/7177  loss 0.6430  lr 0.000218
Step 2800/7177  loss 0.6838  lr 0.000215
[eval] step 2800  val_loss 0.6851
Step 2850/7177  loss 0.5851  lr 0.000212
Step 2900/7177  loss 0.7141  lr 0.000208
Step 2950/7177  loss 0.5120  lr 0.000205
Step 3000/7177  loss 0.8999  lr 0.000202
[eval] step 3000  val_loss 0.6730
Step 3050/7177  loss 0.6280  lr 0.000199
Step 3100/7177  loss 0.6444  lr 0.000195
Step 3150/7177  loss 0.7194  lr 0.000192
Step 3200/7177  loss 0.7498  lr 0.000189
[eval] step 3200  val_loss 0.6644
Step 3250/7177  loss 0.6197  lr 0.000185
Step 3300/7177  loss 0.5095  lr 0.000182
Step 3350/7177  loss 0.7323  lr 0.000179
Step 3400/7177  loss 0.7650  lr 0.000175
[eval] step 3400  val_loss 0.6528
Step 3450/7177  loss 0.5838  lr 0.000172
Step 3500/7177  loss 0.6722  lr 0.000168
Step 3550/7177  loss 0.7291  lr 0.000165
Step 3600/7177  loss 0.6104  lr 0.000162
[eval] step 3600  val_loss 0.6376
Step 3650/7177  loss 0.7026  lr 0.000158
Step 3700/7177  loss 0.6079  lr 0.000155
Step 3750/7177  loss 0.5199  lr 0.000151
Step 3800/7177  loss 0.6461  lr 0.000148
[eval] step 3800  val_loss 0.6340
Step 3850/7177  loss 0.6249  lr 0.000144
Step 3900/7177  loss 0.5792  lr 0.000141
Step 3950/7177  loss 0.8033  lr 0.000137
Step 4000/7177  loss 0.4087  lr 0.000134
[eval] step 4000  val_loss 0.6283
Step 4050/7177  loss 0.6807  lr 0.000131
Step 4100/7177  loss 0.4992  lr 0.000127
Step 4150/7177  loss 0.5023  lr 0.000124
Step 4200/7177  loss 0.4908  lr 0.000120
[eval] step 4200  val_loss 0.6218
Step 4250/7177  loss 0.5609  lr 0.000117
Step 4300/7177  loss 0.6975  lr 0.000114
Step 4350/7177  loss 0.6834  lr 0.000110
Step 4400/7177  loss 0.5422  lr 0.000107
[eval] step 4400  val_loss 0.6138
Step 4450/7177  loss 0.6221  lr 0.000104
Step 4500/7177  loss 0.6484  lr 0.000100
Step 4550/7177  loss 0.5601  lr 0.000097
Step 4600/7177  loss 0.7266  lr 0.000094
[eval] step 4600  val_loss 0.6130
Step 4650/7177  loss 0.8168  lr 0.000091
Step 4700/7177  loss 0.6336  lr 0.000088
Step 4750/7177  loss 0.9077  lr 0.000084
Step 4800/7177  loss 0.5617  lr 0.000081
[eval] step 4800  val_loss 0.6006
Step 4850/7177  loss 0.7046  lr 0.000078
Step 4900/7177  loss 0.5967  lr 0.000075
Step 4950/7177  loss 0.4782  lr 0.000072
Step 5000/7177  loss 0.6561  lr 0.000069
[eval] step 5000  val_loss 0.5992
Step 5050/7177  loss 0.7016  lr 0.000066
Step 5100/7177  loss 0.5048  lr 0.000064
Step 5150/7177  loss 0.6109  lr 0.000061
Step 5200/7177  loss 0.6925  lr 0.000058
[eval] step 5200  val_loss 0.5963
Step 5250/7177  loss 0.5816  lr 0.000055
Step 5300/7177  loss 0.7394  lr 0.000053
Step 5350/7177  loss 0.4383  lr 0.000050
Step 5400/7177  loss 0.5773  lr 0.000048
[eval] step 5400  val_loss 0.5876
Step 5450/7177  loss 0.6214  lr 0.000045
Step 5500/7177  loss 0.6219  lr 0.000043
Step 5550/7177  loss 0.5058  lr 0.000040
Step 5600/7177  loss 0.3985  lr 0.000038
[eval] step 5600  val_loss 0.5865
Step 5650/7177  loss 0.6810  lr 0.000036
Step 5700/7177  loss 0.6661  lr 0.000033
Step 5750/7177  loss 0.6273  lr 0.000031
Step 5800/7177  loss 0.5505  lr 0.000029
[eval] step 5800  val_loss 0.5856
Step 5850/7177  loss 0.5957  lr 0.000027
Step 5900/7177  loss 0.7741  lr 0.000025
Step 5950/7177  loss 0.5056  lr 0.000023
Step 6000/7177  loss 0.5828  lr 0.000022
[eval] step 6000  val_loss 0.5787
Step 6050/7177  loss 0.4433  lr 0.000020
Step 6100/7177  loss 0.5239  lr 0.000018
Step 6150/7177  loss 0.5745  lr 0.000016
Step 6200/7177  loss 0.5607  lr 0.000015
[eval] step 6200  val_loss 0.5801
Step 6250/7177  loss 0.7479  lr 0.000013
Step 6300/7177  loss 0.6549  lr 0.000012
Step 6350/7177  loss 0.6178  lr 0.000011
Step 6400/7177  loss 0.6230  lr 0.000010
[eval] step 6400  val_loss 0.5781
Step 6450/7177  loss 0.5077  lr 0.000008
Step 6500/7177  loss 0.6284  lr 0.000007
Step 6550/7177  loss 0.6249  lr 0.000006
Step 6600/7177  loss 0.5390  lr 0.000005
[eval] step 6600  val_loss 0.5731
Step 6650/7177  loss 0.6468  lr 0.000004
Step 6700/7177  loss 0.3983  lr 0.000004
Step 6750/7177  loss 0.6824  lr 0.000003
Step 6800/7177  loss 0.4819  lr 0.000002
[eval] step 6800  val_loss 0.5743
Step 6850/7177  loss 0.5839  lr 0.000002
Step 6900/7177  loss 0.6298  lr 0.000001
Step 6950/7177  loss 0.5377  lr 0.000001
Step 7000/7177  loss 0.4838  lr 0.000000
[eval] step 7000  val_loss 0.5748
Step 7050/7177  loss 0.6468  lr 0.000000
Step 7100/7177  loss 0.5383  lr 0.000000
Step 7150/7177  loss 0.5753  lr 0.000000
[eval] step 7177  val_loss 0.5731
===========================================
Model name:          xl
Parameters:          85,331,712
Final val loss:      0.5731
Steps in 1 epoch:    7177
Total train tokens:  117,587,968
Wall clock seconds:  1793.4
Wall clock minutes:  29.9
GPU memory start:     328.51 MB
GPU memory end:       1397.31 MB
GPU memory peak:      16261.19 MB
===========================================
